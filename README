# Requisitos de instalación #

En necesario tener previamente instalado:

## Instalación de Ruby ##
* rvm (Linux)
* RubyIntaller (Windows).

## Descargar dependencias ##
Con el siguiente comando parado en el directorio principal de la aplicación:
```
#!bash
   $ bundle install
```
**Nota:** Si bundle no esta instalado correr el siguiente comando:
   
```
#!bash

$ gem install bundle
```


# Entrenar y guardar la red #

```
#!bash

$ cd bin
$ ruby train_an_save_net.rb 100
```


Este comando genera 100 tests mmpi2 con respuestas aleatorias y entrena la red
con 10 iteraciones. Finalmente, guarda la red entrenada en el archivo 
net_trained.dat.
Una vez que tenemos persistida la red, ya no hace falta entrenarla cada vez
que necesitamos usarla.




# Probar la red #


```
#!bash

$ cd bin
$ ruby test_net.rb
```


Este comando prueba la red ya entrenada en el paso anterior, generando un caso
aleatorio para el cual ya se conoce su resultado.




# Realizar el test MMPI2 #

Para realizar el test hay que ejecutar el siguiente comando:


```
#!bash

$ cd bin
$ ruby mmpi2_test.rb
```


Nos va haciendo una serie de preguntas para finalmente darnos nuestro nivel de 
depresión.




# Entrenar y probar la red en un solo paso #

Es posible entrenar y probar la red en un solo paso, aunque puede demorar
algún tiempo dependiendo del cuantos test se usen para entrenar la red.


```
#!bash

$ cd bin
$ ruby train_and_test_net.rb 100

```

Donde 100 es el número de test mmpi2 utilizados para entrenar la red.




# Configurar la red #

La red se puede configurar desde el archivo config/net_configuration. Veamos su 
contenido:

```
#!ruby
module NetConfiguration
	NEURON_LEVELS = [32,32,5]
	# NEURON_LEVELS = [32,32,20] --> Comentado
	LEARNING_RATE = 0.25
	MOMENTUM = 0.1
	MAX_ERROR = 0.001
	OUTPUT_CONVERTER = BinaryOutputConverter.new 5
	# OUTPUT_CONVERTER = BinaryOutputConverter.new 20+1 --> Comentado
end
```

* Neuron Levels: Aqui se configura cuantas neuronas hay en cada nivel y por 
	ende el numero de niveles de la red. En el ejemplo se puede ver que tenemos
	un nivel de entrada de 32 neuronas, uno intermedio de 32 y la salida tiene 
	5 neuronas.
* Learning Rate: Es le factor de aprendizaje de la red. Puede variar entre
  0,05 y 0,25.
* Momentum: Cuanto más grande es el Momento, la convergencia es más rápida. 
	Por defecto es 0,1.
* Error: El máximo error de la red en la etapa de entrenamiento. 
	El error estra expresado como:
	Error = 0.5 * sum( (expected_value-output_value)**2 )
* Output converter: Dependiendo la cantidad de salidas hay dos estrategia:
	
	1. BinaryOutputConverter: Usada para una salida binaria de 5 neuronas.
	2. OutputByNumberConverter: Usada para una salida por cada valor posible.
           Por ejemplo: si tengo 20 valores posible, tendre 20 neuronas de salida.


# Archivo log #

existe un solo log el cual se encunetra en el directorio log. Para leerlo a 
medida que se va generarndo se puede usar el siguieten comando:


```
#!bash

$ tail -f log/mmpi2.log
```





# Correr todos los tests #

Para correr los tests desde el directorio de la aplicación ejecutar el 
siguiente comando: 


```
#!bash

$ rake test

```




# Enlaces en los que esta basada la red #

* [AI4R](http://ai4r.org/neuralNetworks.html)
* [Doumentacion de la red](http://ruby-doc.org/gems/docs/o/omikronn-ai4r-0.1/Ai4r/NeuralNetwork/Backpropagation.html#method-i-train)


# Repositorio de Código Fuente #

* [Repo](https://bitbucket.org/adrianmarino/mmpi2-backpropagation)
* Sistema de control de versiones: [Mercurial](http://mercurial.selenic.com/)